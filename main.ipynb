{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chetan/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer,GPT2Model, GPT2Config, AdamW\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction \n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# import tokenizer for padding\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        for row in reader:\n",
    "            data.append({\n",
    "                'id': row['id'],\n",
    "                'article': row['article'],\n",
    "                'highlights': row['highlights']\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = load_csv('./Dataset/train.csv')\n",
    "test_data = load_csv('./Dataset/test.csv')\n",
    "val_data = load_csv('./Dataset/validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    pattern = r\"(?i)(PUBLISHED:\\s*.\\s*\\d{1,2}:\\d{2}\\s*(EST|PST),\\s*\\d{1,2}\\s\\w+\\s\\d{4}\\s*.\\s*\\|\\s*.\\s*UPDATED:\\s*.\\s*\\d{1,2}:\\d{2}\\s*(EST|PST),\\s*\\d{1,2}\\s\\w+\\s\\d{4})|\" \\\n",
    "              r\"(By\\s*.\\s*[A-Za-z\\s]+.)|\" \\\n",
    "              r\"(\\([A-Za-z\\s]*CNN\\)\\s*--)|\" \\\n",
    "              r\"(Follow\\s*@@[A-Za-z0-9_]+)|\" \\\n",
    "              r\"(UPDATED:\\s*.\\s*\\d{1,2}:\\d{2}\\s*(EST|PST),\\s*\\d{1,2}\\s\\w+\\s\\d{4})|\" \\\n",
    "              r\"(Last\\s*updated\\s*at\\s*\\d{1,2}:\\d{2}\\s*(AM|PM)\\s*on\\s*\\d{1,2}(st|nd|rd|th)\\s*\\w+\\s\\d{4}\\s*.)|\" \\\n",
    "              r\"(\\(CNN\\))\"\n",
    "    \n",
    "    cleaned_text = re.sub(pattern, '', text).strip()\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def clean_articles(data):\n",
    "    for entry in data:\n",
    "        entry['article'] = clean_text(entry['article'])\n",
    "        entry['highlights'] = clean_text(entry['highlights'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# def write_csv(file_path, cleaned_data):\n",
    "#     with open(file_path, mode='w', encoding='utf-8', newline='') as file:\n",
    "#         writer = csv.DictWriter(file, fieldnames=['id', 'article', 'highlights'])\n",
    "#         writer=writer\n",
    "#         writer.writeheader()\n",
    "        \n",
    "#         for row in cleaned_data:\n",
    "#             writer.writerow(row)\n",
    "\n",
    "train_data = clean_articles(train_data)\n",
    "test_data = clean_articles(test_data)\n",
    "val_data = clean_articles(val_data)\n",
    "\n",
    "# write_csv(\"./Cleaned_Dataset/train.csv\", train_data)\n",
    "# write_csv(\"./Cleaned_Dataset/test.csv\", test_data)\n",
    "# write_csv(\"./Cleaned_Dataset/validation.csv\", val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Intialize special Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokken = \"[SUMMARIZE]\"\n",
    "soft_prompt_vocab = [\"[SUMMARIZE]\"]\n",
    "soft_prompt_word2idx = {word: idx for idx, word in enumerate(soft_prompt_vocab)}\n",
    "\n",
    "num_prompts = len([soft_prompt_word2idx[word] for word in prompt_tokken.split()])\n",
    "prompt_id = torch.tensor([soft_prompt_word2idx[word] for word in prompt_tokken.split()])\n",
    "\n",
    "# Initializing Pad tokens\n",
    "pad_token = tokenizer.eos_token\n",
    "tokenizer.add_tokens([pad_token])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenizing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCSV(data):\n",
    "    inp = []\n",
    "    out = []\n",
    "    for row in data:\n",
    "        inp.append(row['article'])\n",
    "        out.append(row['highlights'])\n",
    "    \n",
    "    return inp, out\n",
    "\n",
    "inp_train, out_train = convertCSV(train_data)\n",
    "inp_test, out_test = convertCSV(test_data)\n",
    "\n",
    "train_size = int(0.1 * len(inp_train))\n",
    "inp_train_10 = inp_train[:train_size]\n",
    "out_train_10 = out_train[:train_size]\n",
    "\n",
    "test_size = int(0.1 * len(inp_test))\n",
    "inp_test_10 = inp_test[:test_size]\n",
    "out_test_10 = out_test[:test_size]\n",
    "\n",
    "# print(inp_train[0])\n",
    "\n",
    "#Using NLTK Tokenize\n",
    "\n",
    "inp_train = [word_tokenize(sentence) for sentence in inp_train_10]\n",
    "inp_test = [word_tokenize(sentence) for sentence in inp_test_10]\n",
    "out_train = [word_tokenize(sentence) for sentence in out_train_10]\n",
    "out_test = [word_tokenize(sentence) for sentence in out_test_10]\n",
    "\n",
    "# print(inp_train[0])\n",
    "\n",
    "\n",
    "# def tokenize(data,max_len = 1000):\n",
    "\n",
    "def prepare_data(sentences,pad, max_len=1024):\n",
    "    all_indices = []\n",
    "    for _, sentence in enumerate(sentences):\n",
    "\n",
    "        tokens = tokenizer.encode(sentence,add_special_tokens=True,truncation=True,max_length=max_len)\n",
    "        padded_tokens = torch.tensor(tokens + [tokenizer.convert_tokens_to_ids(pad)] * (max_len - len(tokens)))\n",
    "        \n",
    "        all_indices.append(padded_tokens)\n",
    "        \n",
    "    return all_indices\n",
    "\n",
    "\n",
    "train_inp = prepare_data(inp_train,pad_token,1024-num_prompts)\n",
    "test_inp = prepare_data(inp_test,pad_token,1024-num_prompts)\n",
    "train_out = prepare_data(out_train,pad_token,1024)\n",
    "test_out = prepare_data(out_test,pad_token, 1024)\n",
    "print(len(train_inp[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2SoftPrompt(torch.nn.Module):\n",
    "    def __init__(self, model, num_prompts, emb_size = 768):\n",
    "        super().__init__()\n",
    "        self.gpt2 = GPT2LMHeadModel.from_pretrained(model)\n",
    "        self.prompt = torch.nn.Embedding(num_prompts, emb_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
